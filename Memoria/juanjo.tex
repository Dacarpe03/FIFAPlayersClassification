%\documentclass[a4paper,11pt]{article}
\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphics,graphicx}
\usepackage{amsmath,amssymb,graphics,graphicx}
%%\usepackage[ansinew]{inputenc}
\usepackage[usenames,dvipsnames]{color}
\usepackage[spanish]{babel}
\renewcommand{\spanishtablename}{Tabla}
\usepackage[utf8]{inputenc}
\usepackage{natbib}

\bibpunct{(}{)}{;}{a}{,}{,}

\textheight 24cm \textwidth 17cm \topmargin-2cm
%% \evensidemargin   -0.25cm
\oddsidemargin-0.2cm
%\pagestyle{empty}
\renewcommand{\baselinestretch}{1}

\begin{document}

\title{Plantilla}

\author{{}}

\date{}
\maketitle

%\title{}

%\address{}
Todos los experimentos a continuaci\'on han sido realizados 10 veces y calculando la media de estos.
Adem\'as, para verificar que el cambio realizado es el responsable de la mejora del resultado los cambios han sido at\'omicos, es decir, uno a uno.
	\section{Arquitectura 0: Arquitectura base}

	\label{j-s-a0} %La n es la incial de nuestros nombres, la x el numero de la arquitectura, por ejemplo en mi caso d-s-a3
		En este primer experimentos se ha usado la arquitectura base, \'unicamente el n\'umero de neuronas de cada capa ha sido puesto en multiplos de dos. 
        Por tanto la arquitectura usada ha sido un MLP-4 con [512,256,64,32].
		
		\subsection{Experimento 0}
		\label{j-s-a0-e0} %En mi caso d-s-a3-e4
			Primer experimento sin cambios.
			
			%Tabla con la configuraci\'on. IMPORTANTE PONER EN NEGRITA EL CAMBIO
			\begin{table}[!h]
				\begin{center}
					\begin{tabular}{| c | c | c | c | c | c | c | c |}
						\textbf{Epochs} & \textbf{Learning rate} & \textbf{Batch size} & \textbf{Activation} & \textbf{Optimizer} & \textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
						1000 & 0.1 & 512 & ReLu & SGD & None & None & None &
					\end{tabular}
					\caption{Hiperpar\'ametros para el Experimento 0 y de la Arquitectura 0}
					\label{tab:hip-j-a0-e0}
				\end{center}
			\end{table}
			% Label de la tabla de configuraci\'on IMPORTANTE
			
			Tras realizar 10 veces el experimento con la anterior configuraci\'on, obtenemos los siguientes resultados:
			%Tabla con los resultados, si hemos repetido el experimento varias veces poner media y desviaci\'on est\'andar
			\begin{table}[!h]
				\begin{center}
					\begin{tabular}{ c | c | c | c | c | c |}
						\ & \textbf{Train accuracy (\%)} & \textbf{Validation accuracy (\%)}  \\ \hline
						\textbf{Mean} & 1.00 & 83.00 \\ \hline
						\textbf{Best} & 1.00 & 83.31 \\ \hline
					\end{tabular}
					\caption{Resultados del Experimento 0 y de la Arquitectura 0}
					\label{tab:res-j-a0-e0}
				\end{center}
			\end{table}
		    % Label de la tabla de configuraci\'on IMPORTANTE
		    
		    Como podemos comprobar, el primer problema con el que nos encontramos es el overfitting. Por lo tanto ser\'a esto lo primero que intentaremos solucionar en los siguientes experimentos.

      \subsection{Experimento 1 - A\~{n}adimos Batch Normalization}
		\label{j-s-a0-e1} %En mi caso d-s-a3-e4
			Primer experimento buscando solucionar el overfitting, para ello en este introduciremos Batch-Normalization antes de la funci\'on de activaci\'on.
			
			
			Tras realizar 10 veces el experimento con la anterior configuraci\'on, obtenemos los siguientes resultados:
			%Tabla con los resultados, si hemos repetido el experimento varias veces poner media y desviaci\'on est\'andar
			\begin{table}[!h]
				\begin{center}
					\begin{tabular}{ c | c | c | c | c | c |}
						\ & \textbf{Train accuracy (\%)} & \textbf{Validation accuracy (\%)}  \\ \hline
						\textbf{Mean} & 99.31 & 78.40 \\ \hline
						\textbf{Best} & 98.99 & 79.71 \\ \hline
					\end{tabular}
					\caption{Resultados del Experimento 1 y de la Arquitectura 0}
					\label{tab:res-j-a0-e1}
				\end{center}
			\end{table}
		    % Label de la tabla de configuraci\'on IMPORTANTE
		    
		    A la vista de los resultados, el overfitting persiste en el modelo por lo que habr\'a que seguir buscando la manera de solucionarlo.

      \subsection{Experimento 2 - A\~{n}adimos Regularizaci\'on L1-L2}
		\label{j-s-a0-e2} %En mi caso d-s-a3-e4
			En este segundo experimento buscando solucionar el overfitting introducimos la regularizaci\'on L1-L2 con el objetivo de regularizar los pesos de nuestro modelo y que de esta forma el modelo no sobre aprenda.
            Es por tanto que en cada capa densa de nuestro modelo a\~{n}adimos lo siguiente:
            
            kernel\_regularizer=regularizers.L1L2(l1=0.001,l2=0.1)
			
			
			Tras realizar 10 veces el experimento con la anterior configuraci\'on, obtenemos los siguientes resultados:
			%Tabla con los resultados, si hemos repetido el experimento varias veces poner media y desviaci\'on est\'andar
			\begin{table}[!h]
				\begin{center}
					\begin{tabular}{ c | c | c | c | c | c |}
						\ & \textbf{Train accuracy (\%)} & \textbf{Validation accuracy (\%)}  \\ \hline
						\textbf{Mean} & 75.20 & 76.18 \\ \hline
						\textbf{Best} & 78.10 & 75.40 \\ \hline
					\end{tabular}
					\caption{Resultados del Experimento 2 y de la Arquitectura 0}
					\label{tab:res-j-a0-e1}
				\end{center}
			\end{table}
		    % Label de la tabla de configuraci\'on IMPORTANTE
		    
		    Como podemos ver, el overfitting se ha solucionado por lo que es el momento de mejorar ese accuracy.
      
      \subsubsection{Experimento 2.1 - Regularizaci\'on L1-L2 sin Batch-Normalization}
		\label{j-s-a0-e2.1} %En mi caso d-s-a3-e4
			Este experimento lo realizamos con el objetivo de comprobar si lo que ha solucionado el overfitting ha sido el Batch-Normalization junto a la regularizaci\'on L1-L2 o la regularizaci\'on por si sola ser\'ia capaz de solucionarlo.
			
			Tras realizar 10 veces el experimento con la anterior configuraci\'on, obtenemos los siguientes resultados:
			%Tabla con los resultados, si hemos repetido el experimento varias veces poner media y desviaci\'on est\'andar
			\begin{table}[!h]
				\begin{center}
					\begin{tabular}{ c | c | c | c | c | c |}
						\ & \textbf{Train accuracy (\%)} & \textbf{Validation accuracy (\%)}  \\ \hline
						\textbf{Mean} & 47.64 & 49.97 \\ \hline
						\textbf{Best} & 53.30 & 56.38 \\ \hline
					\end{tabular}
					\caption{Resultados del Experimento 2.1 y de la Arquitectura 1}
					\label{tab:res-j-a0-e2.1}
				\end{center}
			\end{table}
		    % Label de la tabla de configuraci\'on IMPORTANTE
      
		    A partir de los resultados de la Tabla \ref{tab:res-j-a0-e2.1} el modelo no aprende si introducimos la regularizaci\'on sin usar el Batch-Normalization.
      
     
    \subsection{Ronda de experimentos 3 - Buscando el mejor Batch size}
		\label{j-s-a0-e3} %En mi caso d-s-a3-e4
			En esta ronda de experimentos el objetivo es encontrar el Batch size con el que mejor resultado obtenemos.
            
			%Tabla con la configuraci\'on. IMPORTANTE PONER EN NEGRITA EL CAMBIO
			\begin{table}[h!]
				\begin{center}
					\begin{tabular}{| c | c | c | c | c | c | c |}
						\textbf{Epochs} & \textbf{Learning rate} & \textbf{Activation} & \textbf{Optimizer} & \textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
						1000 & 0.1 & ReLu & SGD & L1L2 & None & None &
					\end{tabular}
					\caption{Hiperpar\'ametros para esta ronda de experimentos y usando la arquitectura 0}
					\label{tab:hip-j-a0-e3}
				\end{center}
			\end{table}
			% Label de la tabla de configuraci\'on IMPORTANTE
			
			Tras realizar 10 veces el experimento para cada Batch size con la anterior configuraci\'on, obtenemos los siguientes resultados:
			%Tabla con los resultados, si hemos repetido el experimento varias veces poner media y desviaci\'on est\'andar
                \begin{table}[h!]
                \begin{tabular}{c|cccc}
                \hline
                \textbf{Batch size} &
                  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
                  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
                  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
                  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
                64   & 70.81 & 75.27 & 70.94 & 76.55 \\
                128  & 72.78 & 77.01 & 72.81 & 78.66 \\
                256  & 74.17 & 77.51 & 74.37 & 79.21 \\
                512  & 75.20 & 76.18 & 75.40 & 78.10 \\
                1024 & 77.00 & 79.85 & 77.29 & 81.01 \\
                2048 & 79.71 & 78.13 & 78.33 & 81.27 \\
                \textbf{4096} & \textbf{79.73} & \textbf{79.91} & \textbf{80.45} & \textbf{81.14} \\
                8192 & 79.97 & 76.40 & 79.93 & 79.71 \\ \hline
                \end{tabular}

                \caption{Resultados de la ronda de experimentos 3 y usando la arquitectura 0}
                \label{tab:res-j-a0-e3}
                \end{table}
		    % Label de la tabla de configuraci\'on IMPORTANTE
		    
		    A ra\'iz de los anteriores resultados se ha tomado la decisi\'on de utilizar 4096 como valor para el Batch size, ya que este es el que obtiene los mejores resultados en el conjunto de validaci\'on obteniendo un 79.91 (\%)

      \subsection{Ronda de experimentos 4 - Buscando la mejor estructura}
		\label{j-s-a0-e4} %En mi caso d-s-a3-e4
			Una vez definido el tama\~{n}o de Batch, el siguiente paso ser\'a encontrar la mejor arquitectura. En la Tabla \ref{tab:hip-j-a0-e4} veremos los hiperpar\'ametros que ser\'an utilizados para todas las arquitecturas evaluadas.
            
			%Tabla con la configuraci\'on. IMPORTANTE PONER EN NEGRITA EL CAMBIO
			\begin{table}[h!]
				\begin{center}
					\begin{tabular}{| c | c | c | c | c | c | c | c |}
						\textbf{Epochs} & \textbf{Learning rate} & \textbf{Batch size} & \textbf{Activation} & \textbf{Optimizer} & \textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
						1000 & 0.1 & 4096 & ReLu & SGD & L1L2 & None & None &
					\end{tabular}
					\caption{Hiperpar\'ametros para esta ronda de experimentos y usando la arquitectura 0}
					\label{tab:hip-j-a0-e4}
				\end{center}
			\end{table}
			% Label de la tabla de configuraci\'on IMPORTANTE
			
			Tras realizar 10 veces el experimento para cada arquitectura con la anterior configuraci\'on, obtenemos los siguientes resultados:
			%Tabla con los resultados, si hemos repetido el experimento varias veces poner media y desviaci\'on est\'andar
\begin{center}
\begin{table}[h!]
\begin{tabular}{c|cccc}
\hline
\textbf{Arquitectura} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
{[}8,4{]}                 & 79.21          & 80.59          & 79.81          & 81.38          \\
{[}32,16{]}               & 80.39          & 80.78          & 81.12          & 81.38          \\
{[}256,128{]}             & 80.04          & 80.73          & 79.93          & 81.69          \\
{[}512,256{]}             & 79.96          & 80.57          & 80.09          & 81.07          \\
{[}16,8,4{]}              & 79.51          & 81.19          & 79.73          & 82.19          \\
\textbf{{[}32,16,8{]}}    & \textbf{80.05} & \textbf{81.27} & \textbf{79.67} & \textbf{82.32} \\
{[}64,32,16{]}            & 79.99          & 80.76          & 79.98          & 81.38          \\
{[}256,64,32{]}           & 79.84          & 80.62          & 80.25          & 81.51          \\
{[}512,256,128{]}         & 80.08          & 78.66          & 79.81          & 80.70          \\
{[}64,32,16,8{]}          & 79.45          & 79.91          & 79.83          & 80.95          \\
{[}256,64,32,16{]}        & 79.60          & 80.13          & 79.02          & 81.01          \\
{[}1024,512,256,64{]}     & 80.15          & 79.80          & 81.17          & 80.83          \\
{[}512, 256, 64, 32{]}    & 79.73          & 79.91          & 80.45          & 81.14          \\
{[}2048,1024,512,256{]}   & 80.02          & 79.72          & 79.80          & 80.83          \\
{[}32,16,16,8,8{]}        & 79.33          & 80.08          & 78.75          & 80.89          \\
{[}32,32,16,16,8{]}       & 79.36          & 79.98          & 78.78          & 80.83          \\
{[}1024,512,256,128,64{]} & 80.52          & 78.61          & 81.78          & 79.83          \\ \hline
\end{tabular}

                \caption{Resultados de la ronda de experimentos 4 usando la arquitectura de la primera columna}
                \label{tab:res-j-a0-e4}
                \end{table}
                \end{center}
		    % Label de la tabla de configuraci\'on IMPORTANTE
		    
		    Como podemos observar, en este caso estructura con la que mejor accuracy en el conjunto de validación obtenemos es una MLP3 con [32,16,8] neuronas por capa respectivamente.
      \newpage
\subsection{Ronda de experimentos 5 - Buscando el mejor Learning Rate}  
En esta ronda de experimentos nuestro objetivo es encontrar el mejor valor para el learning rate. 

		    %Tabla con la configuraci\'on. IMPORTANTE PONER EN NEGRITA EL CAMBIO
			\begin{table}[h!]
				\begin{center}
					\begin{tabular}{| c | c | c | c | c | c | c | c |}
						\textbf{Arquitectura} & \textbf{Epochs} & \textbf{Batch size} & \textbf{Activation} & \textbf{Optimizer} & \textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
						[32,16,8] & 1000 & 4096 & ReLu & SGD & L1L2 & None & None &
					\end{tabular}
					\caption{Hiperpar\'ametros para esta ronda de experimentos y usando la arquitectura 0}
					\label{tab:hip-j-a0-e5}
				\end{center}
			\end{table}
			% Label de la tabla de configuraci\'on IMPORTANTE
			
			Tras realizar 10 veces el experimento para cada valor de learning rate con la anterior configuraci\'on, obtenemos los siguientes resultados:

   \begin{table}[h!]
\begin{tabular}{c|cccc}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Learning Rate\\ Fijo\end{tabular}} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
0.1    & 80.32 & 81.13 & 79.96 & 81.63 \\
0.01   & 83.17 & 83.07 & 83.12 & 83.43 \\
0.001  & 69.33 & 69.03 & 72.94 & 73.51 \\
0.0001 & 58.81 & 56.79 & 61.14 & 59.11 \\ \hline
\end{tabular}
\caption{Resultados de la ronda de experimentos 5}
\label{tab:res-j-a0-e5}
\end{table}

En este caso, nos hemos dado cuenta que cuando el learning rate = 0.001 el mejor resultado es obtenido en la epoch 1000, lo que nos indica que si continuaramos entrenando este podría mejorar. Por lo que el próximo experimento lo haremos con la configuración siguiente:

\begin{table}[h!]
				\begin{center}
					\begin{tabular}{| c | c | c | c | c | c | c | c |}
						\textbf{Arquitectura} & \textbf{Epochs} & \textbf{Batch size} & \textbf{Activation} & \textbf{Optimizer} & \textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
						[32,16,8] & 5000 & 4096 & ReLu & SGD & L1L2 & None & None &
					\end{tabular}
					\caption{Hiperpar\'ametros para esta ronda de experimentos.}
					\label{tab:hip-j-a0-e5.1}
				\end{center}
			\end{table}
   A partir de los hiperparámetros anteriores obtenemos el siguiente resultado:
   \begin{table}[h!]
\begin{tabular}{c|cccc}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Learning Rate\\ Fijo\end{tabular}} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
0.001  & 85.10 & 83.53 & 85.05 & 84.18 \\ \hline
\end{tabular}
\caption{Resultado para un learning rate = 0.001 con 5000 epochs.}
\label{tab:res-j-a0-e6}
\end{table}

Como podemos comprobar en la Tabla \ref{tab:res-j-a0-e6}, este valor de learning rate es el mejor que hemos encontrado, y por lo tanto, el que utilizaremos para los siguientes experimentos.

\subsection{Ronda de experimentos 5.1 - Buscando el mejor Learning Rate}
Antes de continuar con otros hiperparámetros nos planteamos el uso del callback ReduceLROnPlateau en nuestro modelo para comprobar si con este obtenemos un mejor resultado que usando un learning rate fijo tal y como se ha empleando en el experimento anterior.
Por tanto el callback utilizado es el siguiente:
ReduceLROnPlateau('val\_categorical\_accuracy', factor=0.1, patience=300, verbose=1)
Los settings para este experimento se pueden ver en la Tabla \ref{tab:hip-j-a0-e5.1}.

\begin{table}[h!]
\begin{tabular}{c|cccc}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Learning Rate\\ Inicial\end{tabular}} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
1     & 63.71 & 59.46 & 67.32 & 68.73 \\
0.1   & 80.82 & 81.64 & 81.17 & 82.28 \\
0.01  & 62.81 & 62.63 & 78.64 & 79.21 \\
0.001 & 84.48 & 83.38 & 84.22 & 83.31 \\\hline
\end{tabular}
\caption{Resultado para un learning rate = 0.001 con 5000 epochs.}
\label{tab:res-j-a0-e7}
\end{table}

Como podemos ver en la Tabla \ref{tab:res-j-a0-e7} no conseguimos superar los resultados obtenidos con el learning rate fijo a 0.001 durante todo el entrenamiento.

 \subsection{Ronda de experimentos 6 - Buscando la mejor función de activación}

 \begin{table}[h!]
				\begin{center}
                \hline
				\begin{tabular}{| c | c | c | c | c | c | c | c |}
						\textbf{Arquitectura} & \textbf{Epochs} & \textbf{Batch size} & \textbf{Learning Rate} & \textbf{Optimizer} & \textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
						[32,16,8] & 5000 & 4096 & 0.001 & SGD & L1L2 & None & None \\ \hline
					\end{tabular}
					\caption{Hiperpar\'ametros para esta ronda de experimentos.}
					\label{tab:hip-j-a0-e8}
				\end{center}
			\end{table}

   
 \begin{table}[h!]
\begin{tabular}{c|cccc}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Función de\\ activación\end{tabular}} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
\textbf{ReLu} & \textbf{85.10} & \textbf{83.53} & \textbf{85.05} & \textbf{84.18} \\
Elu           & 82.45          & 83.36          & 82.52          & 83.68          \\
Tanh          & 82.46          & 83.01          & 82.67          & 83.68          \\ \hline
\end{tabular}
\caption{Resultados para cada función de activación.}
\label{tab:res-j-a0-e8}
\end{table}

\subsection{Ronda de experimentos 7 - Inicializador}

 \begin{table}[h!]
    \begin{center}
    \hline
    \begin{tabular}{| c | c | c | c | c | c | c | c | c |}
            \textbf{Arquitechture} & \textbf{Epochs} & \textbf{Batch size} & \textbf{Learning Rate} & \textbf{Optimizer} & \textbf{Activation} &\textbf{Regularization} & \textbf{Initializer} & \textbf{Dropout}\\ \hline
            [32,16,8] & 5000 & 4096 & 0.001 & SGD & ReLu & L1L2 & None & None \\ \hline
        \end{tabular}
        \caption{Hiperpar\'ametros para esta ronda de experimentos.}
        \label{tab:hip-j-a0-e8}
    \end{center}
\end{table}

\begin{table}[h!]
\begin{tabular}{c|cccc}
\hline
\textbf{Inicializador} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Mean\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Train accuracy (\%) \\ Best\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Validation accuracy (\%) \\ Best\end{tabular} \\ \hline
Ninguno             & 85.10          & 83.53          & 85.05          & 84.18          \\
He Normal           & 84.87          & 83.66          & 84.70          & 84.36          \\
\textbf{He Uniform} & \textbf{84.83} & \textbf{83.73} & \textbf{84.94} & \textbf{84.24} \\
Uniform (-0.1,0.1)  & 84.11          & 83.34          & 84.78          & 83.93          \\ \hline
\end{tabular}
\caption{Resultados para cada inicializador.}
\label{tab:res-j-a0-e9}
\end{table}

\end{document}
